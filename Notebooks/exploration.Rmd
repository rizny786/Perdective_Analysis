---
title: "Assignment 2"
author: "Rizny Mubarak"
date: "2023-09-05"
output: pdf_document
---

```{r}
# Load necessary libraries
library(forecast)
library(tsutils)
```

## Level A

### 1. Loading Data

```{r}
# Load data from csv file
Y <- read.csv("./workshop1R.csv")
# Pick the first time series for modelling
y <- Y[,1]
# Transform it into a time series
y <- ts(y,frequency=12)
```

### 2. Constructing estimation and hold-out sets

```{r}
y.tst <- tail(y,12)
y.trn <- head(y,48)
print(y.trn)
```

### 3. Exploration

```{r}
cma <- cmav(y.trn,outplot=1)
```

```{r}
seasplot(y.trn)
```

### 4. Forecasting

#### 4.1 Model fitting

```{r}
ets(y.trn,model="ANN")
```

```{r}
fit1 <- ets(y.trn,model="ANN")
print(fit1)
```

```{r}
plot(fit1)
```

```{r}
class(fit1)
```

```{r}
names(fit1)
```

```{r}
fit1$fitted
```

```{r}
plot(y.trn)
lines(fit1$fitted, col="red")
```

```{r}
fit2 <- ets(y.trn, model = "ANN", alpha = 0.1)
plot(y.trn)
lines(fit2$fitted,col="blue")
```

```{r}
fit1$mse
```

```{r}
fit2$mse
```

#### 4.2 Forecasting

```{r}
frc1 <- forecast(fit1, h=12)
print(frc1)
```

```{r}
plot(frc1)
```

```{r}
plot(frc1)
lines(fit1$fitted,col="red")
```

```{r}
names(frc1)
```

```{r}
frc2 <- forecast(fit2,h=12) # Store the forecasts
plot(frc1)
lines(fit1$fitted,col="blue")
lines(frc2$mean,col="red")
lines(fit2$fitted,col="red")
lines(frc2$lower[,2],col="red") # 95% lower
lines(frc2$upper[,2],col="red") # 95% upper
lines(y.tst,lty=2) 
# Add legend to the plot
legend("topleft",c("Forecast 1","Forecast 2"),col=c("blue","red"),lty=1)
```

```{r}
MAE1 <- mean(abs(y.tst - frc1$mean))
MAE2 <- mean(abs(y.tst - frc2$mean))
MAE <- c(MAE1, MAE2) 
names(MAE) <- paste0("Forecast ",1:2) 
round(MAE,3)
```

#### 4.3 Model selection

```{r}
fit3 <- ets(y.trn, model= "AAA", damped=TRUE)
frc3 <- forecast(fit3,h=12)
print(fit3)
```

```{r}
plot(frc1)
lines(fit1$fitted,col="blue")
lines(frc3$mean,col="red",lwd=2) # lwd=2 makes the line thicker
lines(fit3$fitted,col="red")
lines(frc3$upper[,2],col="red")
lines(frc3$lower[,2],col="red")
lines(y.tst,lty=2)
legend("topleft",c("Forecast 1","Forecast 3"),col=c("blue","red"),lty=1)
```

```{r}
MAE3 <- mean(abs(y.tst - frc3$mean))
round(MAE3,3)
```

```{r}
round(MAE,3)
```

```{r}
MSE1 <- mean((y.tst - frc1$mean)^2)
MSE2 <- mean((y.tst - frc2$mean)^2)
MSE3 <- mean((y.tst - frc3$mean)^2)
MSE <- c(MSE1, MSE2, MSE3) 
RMSE <- sqrt(MSE) 
names(RMSE) <- paste0("Forecast ",1:3) 
round(RMSE,3)
```

```{r}
crit <- array(NA,c(3,3))
print(crit)
```

```{r}
crit <- array(NA,c(3,3),dimnames=list(c("Forecast 1", "Forecast 2", "Forecast 3"),
c("AIC","AICc","BIC"))) # I can split lines!
print(crit)
```

```{r}
models <- list(fit1, fit2, fit3)

for (i in 1:3) {
  crit[i, "AIC"] <- models[[i]]$aic
  crit[i, "AICc"] <- models[[i]]$aicc
  crit[i, "BIC"] <- models[[i]]$bic
}

print(crit)
```

```{r}
fit4 <- ets(y.trn)
print(fit4)
```

# Exercise 

"To enhance both conciseness and clarity within this report, the subsequent sections will adopt the following terminology conventions in the forthcoming code:

1\. "fit_a" will be employed when specifying an ANN model with automatic alpha selection.

2\. "fit_u" will be utilized when denoting an ANN model with an explicitly specified upper alpha value.

3\. "fit_l" will be employed when delineating an ANN model with a specifically defined lower alpha value.

Moreover, these identical nomenclature conventions will be consistently applied to the forecasting variable, which will uniformly be denoted as "frc" in all relevant code sections."

## Level B

### 1. Loading Data

```{r}
y <- Y[,2]
# Transform it into a time series
y <- ts(y,frequency=12)
```

### 2. Constructing estimation and hold-out sets

```{r}
y.tst <- tail(y,12)
y.trn <- head(y,48)
```

### 3. Exploration

```{r}
cma <- cmav(y.trn,outplot=1)
```

```{r}
seasplot(y.trn)
```

### 4. Forecasting

#### 4.1 Model fitting

```{r}
# Automatic Alpha ANN
fit_a <- ets(y.trn,model="ANN")
print(fit_a)
```

```{r}
# Upper Alpha ANN
fit_u <- ets(y.trn,model="ANN", alpha = 0.08 )
print(fit_u)
```

```{r}
# Lower Alpha ANN
fit_l <- ets(y.trn,model="ANN", alpha = 0.02 )
print(fit_l)
```

```{r}
cirt <- array(NA, c(3, 3), dimnames = list(c("Automatic", "Upper", "Lower"),
                                         c("MSE", "AIC", "AICc","BIC")))

models <- list(fit1, fit2, fit3)

for (i in 1:3) {
  # Use 'cirt' instead of 'crit' for assignment
  cirt[i, "MSE"] <- models[[i]]$mse
  cirt[i, "AIC"] <- models[[i]]$aic
  cirt[i, "AICc"] <- models[[i]]$aicc
  cirt[i, "BIC"] <- models[[i]]$bic
}

print(cirt)
```

#### 4.2 Forecasting

-   Forecast ANN

```{r}
# ploting Automatic ANN
frc_a <- forecast(fit_a, h=12)
plot(frc1, main = "Forcast Automatic ANN")
lines(fit1$fitted,col="blue")
```

-   Forecast ANN and Upper Alpha

```{r}
# ploting Upper vs ANN
frc_u <- forecast(fit2,h=12)
plot(frc_a, main = "Forcast ANN, Automatic vs Upper Alpha")
lines(fit_a$fitted,col="blue")
lines(frc_u$mean,col="red")
lines(fit_u$fitted,col="red")
lines(frc_u$lower[,2],col="red") # 95% lower
lines(frc_u$upper[,2],col="red") # 95% upper
lines(y.tst,lty=2) 

# legends
legend("topleft",c("ANN Automatic","ANN Upper Alpha"),col=c("blue","red"),lty=1)
```

-   Forecast ANN and Lower Alpha

```{r}
# Ploting Lower vs ANN
frc_l <- forecast(fit_l,h=12)
plot(frc_a)
lines(fit_a$fitted,col="blue")
lines(frc_l$mean,col="red")
lines(fit_l$fitted,col="red")
lines(frc_l$lower[,2],col="red") # 95% lower
lines(frc_l$upper[,2],col="red") # 95% upper
lines(y.tst,lty=2) 

# Add legend to the plot
legend("topleft",c("ANN Automatic","ANN Lower Alpha"),col=c("blue","red"),lty=1)
```

-   Forecast ANN, Upper Alpha and Lower Alpha

#### 4.3 Model selection

```{r}
# Mean Absolute Error
MAE_a <- mean(abs(y.tst - frc_a$mean))
MAE_u <- mean(abs(y.tst - frc_u$mean))
MAE_u <- mean(abs(y.tst - frc_u$mean))

#Mean Square Error
MSE_a <- mean((y.tst - frc_a$mean)^2)
MSE_u <- mean((y.tst - frc_u$mean)^2)
MSE_l <- mean((y.tst - frc_l$mean)^2)

# Root Mean Square Error
RMSE_a <- sqrt(MSE_a)
RMSE_u <- sqrt(MSE_u)
RMSE_l <- sqrt(MSE_l)
```

```{r}

```

### Answers

-   Which one is best using your judgement?

-   Which one is best using errors?

-   Does the selected model perform best in the out-of-sample data?
